{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T15:44:28.743513Z",
     "start_time": "2018-01-21T15:44:28.663967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN 초간단 정리\n",
    "- Discriminator\n",
    "    - 784, 256\n",
    "    - ReLU\n",
    "    - 256, 256\n",
    "    - ReLU\n",
    "    - 256, 1\n",
    "    - Sigmoid\n",
    "- Generator\n",
    "    - 64, 256\n",
    "    - ReLU\n",
    "    - 256, 256\n",
    "    - 256, 784\n",
    "    - Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T15:43:19.545426Z",
     "start_time": "2018-01-21T15:43:19.521024Z"
    }
   },
   "outputs": [],
   "source": [
    "D = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(64, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 784),\n",
    "    nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T15:44:54.080467Z",
     "start_time": "2018-01-21T15:44:54.077244Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5), \n",
    "                                     std=(0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T15:44:54.948534Z",
     "start_time": "2018-01-21T15:44:54.887816Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST(root='./data/',\n",
    "                       train=True,\n",
    "                       transform=transform,\n",
    "                       download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T16:09:00.104802Z",
     "start_time": "2018-01-21T16:09:00.101669Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T15:53:34.236705Z",
     "start_time": "2018-01-21T15:53:34.189419Z"
    }
   },
   "source": [
    "### torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=<function default_collate at 0x1093ef048>, pin_memory=False, drop_last=False)\n",
    "\n",
    "### Docstring:     \n",
    "Data loader. Combines a dataset and a sampler, and provides\n",
    "single- or multi-process iterators over the dataset.\n",
    "\n",
    "### Arguments:\n",
    "- dataset (Dataset): dataset from which to load the data.  \n",
    "- batch_size (int, optional): how many samples per batch to load(default: 1).  \n",
    "- shuffle (bool, optional): set to ``True`` to have the data reshuffled at every epoch (default: False).  \n",
    "- sampler (Sampler, optional): defines the strategy to draw samples from the dataset. If specified, ``shuffle`` must be False.  \n",
    "- batch_sampler (Sampler, optional): like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
    "- num_workers (int, optional): how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process(default: 0)  \n",
    "- collate_fn (callable, optional): merges a list of samples to form a mini-batch.  \n",
    "- pin_memory (bool, optional): If ``True``, the data loader will copy tensors into CUDA pinned memory before returning them.  \n",
    "- drop_last (bool, optional): set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T15:45:40.893179Z",
     "start_time": "2018-01-21T15:45:40.889951Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    D.cuda()\n",
    "    G.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T16:05:14.823350Z",
     "start_time": "2018-01-21T16:05:14.820851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-21T16:09:08.586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:767: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.312897\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.399529\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.485228\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.569799\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.593847\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.619501\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.648684\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.681005\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.716059\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.753416\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.792627\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.833277\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.875092\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.917604\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.960199\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.003054\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.046034\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.088905\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.131559\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.173735\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.215425\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.256256\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.296507\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.335909\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.374388\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.411737\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.447899\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.482796\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.516943\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.550268\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.582649\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.612541\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.641821\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.669949\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.697538\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.724585\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.750252\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.775139\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.799044\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.820436\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.841528\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.861456\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.881248\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.900763\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.920076\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.939238\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.958111\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.946135\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.929266\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.917425\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.906990\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.900620\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.864067\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.788332\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.669024\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.380823\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.207853\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.169214\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.178932\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.186638\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.197268\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.210543\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.225952\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.243408\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.262300\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.282717\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.304541\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.327423\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.342419\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.356783\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.372801\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.390356\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.409157\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.428827\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.448845\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.469263\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.412498\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.364143\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.323732\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.284182\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.251585\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.225710\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.206057\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.190702\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.180111\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.168142\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.142729\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.110407\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.961712\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.879087\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.867891\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.893478\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.923948\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.959105\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.997435\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.038338\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.081398\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.125393\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.164915\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.206535\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.248568\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.291407\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.333643\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.376732\n",
      "Epoch [5/200], Discriminator Loss: 0.000001, Generator Loss: 20.418798\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.460852\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.505421\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.538084\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.576540\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.614624\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.652441\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.689821\n",
      "Epoch [5/200], Discriminator Loss: 0.000001, Generator Loss: 20.628670\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.576689\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.533567\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.498507\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.470831\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.448614\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.432741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.422632\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.417824\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.417730\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.421968\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.429962\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.441498\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.455931\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.473099\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.492582\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.514088\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.535131\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.557833\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.581812\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.598509\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.617029\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.637148\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.659052\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.665730\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.662857\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.635332\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.465881\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.240227\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.923782\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.602570\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.546648\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.586554\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.645477\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.707888\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.772955\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.839851\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.907928\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.976439\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.044920\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.112921\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.180079\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.245970\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.310057\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.372564\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.433464\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.492529\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.549690\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.605009\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.658232\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.709597\n",
      "Epoch [5/200], Discriminator Loss: 0.000002, Generator Loss: 20.757317\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.803347\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.847780\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.890617\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.931887\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.971722\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.009306\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.045500\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.080330\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.114006\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.146475\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.177830\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.208096\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.237303\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.265530\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.292841\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.291616\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.291599\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.293362\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.296274\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.300686\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.306513\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.297127\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.290525\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.286377\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.284519\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.284666\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.286629\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.290285\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.295408\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.301868\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.309460\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.318123\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.326424\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.335693\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.345430\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.355843\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.366966\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.378681\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.390755\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.403294\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.416225\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.429449\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.442993\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.456579\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.470806\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.472412\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.309576\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.060772\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.306898\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.604231\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.566179\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.604471\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.632051\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.641268\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.674120\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.730413\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.796995\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.865324\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 19.934595\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.004053\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.073456\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.142120\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.209839\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.276335\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.339256\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.400848\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.460815\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.519014\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.575438\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.630102\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.682955\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.733913\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.765623\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.796902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.828096\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.854219\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.880623\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.907316\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.934080\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.960848\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.987661\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.014307\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.040796\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.067114\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.093134\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.110712\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.128756\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.147215\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.165014\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.182961\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.201323\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.219934\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.238741\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.257597\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.276609\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.295630\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.314627\n",
      "Epoch [5/200], Discriminator Loss: 0.000007, Generator Loss: 21.323065\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.332392\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.333075\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.345884\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.226717\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.962347\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.564655\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.518465\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.539797\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.563082\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.587770\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.613894\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.641228\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.669405\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.698338\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.715334\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.734037\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.754278\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.775782\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.798347\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.821867\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.846045\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.870493\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.895479\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.920786\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.944609\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.968845\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 20.993261\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.017359\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.041391\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.064238\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.086538\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.107798\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.129284\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.150358\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.170897\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.191561\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.212374\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.233156\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.253935\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.274683\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.295321\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.315813\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.335701\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.355469\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.375093\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.394533\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.413816\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.432884\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.451754\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.470345\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.488747\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.506865\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.524809\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.542488\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.559952\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.577156\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.594124\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.610838\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.627085\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.643154\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.658943\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.674562\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.689915\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.704971\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.719698\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.733372\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.745699\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.757540\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.769180\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.780918\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.792702\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.804436\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.816154\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.825220\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.834560\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.844023\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.848740\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.854027\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.859892\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.866188\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.872566\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.879417\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.886690\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.894264\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.902128\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.910294\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.918100\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.926163\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.934464\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.942984\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.951658\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.960476\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.969088\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.974123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.979649\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.985619\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.991970\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 21.998672\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.005705\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.012932\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.020370\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.022058\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.023794\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.026340\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.029539\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.033358\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.037710\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.042587\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.047701\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.048124\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.049475\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.051620\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.053797\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.056643\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.060163\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.064217\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.068840\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.073837\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.079079\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.084709\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.090605\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.096901\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.103405\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.110132\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.117033\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.124052\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.131321\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.137476\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.143930\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.150549\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.157366\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.163088\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.169035\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.175186\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.181551\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.188091\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.194798\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.201632\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.208582\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.215599\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.222763\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.229467\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.236242\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.243172\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.249729\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.254854\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.259655\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.264782\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.270124\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.275661\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.278677\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.282087\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.285887\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.290047\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.294567\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.299339\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.304420\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.309681\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.314541\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.319607\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.324944\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.330433\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.336071\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.341883\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.347790\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.353788\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.359953\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.366184\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.372448\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.378796\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.382435\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.386389\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.390648\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.394621\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.397713\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.401209\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.404871\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.408665\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.412731\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.417078\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.421608\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.426296\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.431242\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.436287\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.441004\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.444822\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.448885\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.453230\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.457518\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.462004\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.466663\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.471052\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.475588\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.480337\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.485214\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.490227\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.495338\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.500511\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.505835\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.510832\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.515297\n",
      "Epoch [5/200], Discriminator Loss: 0.000002, Generator Loss: 22.517422\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.519913\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.522732\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.525885\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.529305\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.532967\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.531746\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.531258\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.531408\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.532143\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.533424\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.535133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.537249\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.539711\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.542568\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.545681\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.549044\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.552517\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.555578\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.555418\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.555262\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.555687\n",
      "Epoch [5/200], Discriminator Loss: 0.000010, Generator Loss: 22.541100\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.528538\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.517736\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.508656\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.501110\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.494896\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.489967\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.486092\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.482668\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.479979\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.478167\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.477184\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.476938\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.477322\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.478357\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.479891\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.481926\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.483997\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.486486\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.489368\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.492586\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.496101\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.499729\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.503557\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.507656\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.511208\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.514997\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.518223\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.521736\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.525545\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.529549\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.533781\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.536970\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.540394\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.544182\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.547209\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.550539\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.554176\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.557999\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.562035\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.559900\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.557594\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.555265\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.553734\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.552980\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.552889\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.552513\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.552820\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.552986\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.553799\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.555092\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.556883\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.559074\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.561613\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.564480\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.567713\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.571184\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.574928\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.578859\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.579994\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.581654\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.583717\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.586098\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.588869\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.591953\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.595318\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.598879\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.601316\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.604088\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.607149\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.608641\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.610594\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.612904\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.615568\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.618547\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.621819\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.625271\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.629011\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.632917\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.636965\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.641201\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.645153\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.648689\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.651588\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.654699\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.658096\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.661650\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.665501\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.669344\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.673367\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.677584\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.681887\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.686287\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.690811\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.695417\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.696047\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.695583\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.695774\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.696392\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.697502\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.698982\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.700905\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.698841\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.697536\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.696917\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.696884\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.697372\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.698376\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.695890\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.694225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.693249\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.692879\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.693123\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.689949\n",
      "Epoch [5/200], Discriminator Loss: 0.000000, Generator Loss: 22.687639\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.001)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        batch_size = images.size(0)\n",
    "        images = Variable(images.view(batch_size, -1))\n",
    "        \n",
    "        real_labels = Variable(torch.ones(batch_size))\n",
    "        fake_labels = Variable(torch.zeros(batch_size))\n",
    "        # GPU를 사용할 땐 x = x.cuda()를 하고 Variable(x)를 return\n",
    "        \n",
    "        # Train discriminator\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_scroe = outputs\n",
    "        \n",
    "        z = Variable(torch.randn(batch_size, 64))\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_scroe = outputs\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        z = Variable(torch.randn(batch_size, 64))\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print ('Epoch [{}/{}], Discriminator Loss: {:4f}, Generator Loss: {:4f}'.format(\n",
    "                epoch+1, num_epochs, d_loss.data[0], g_loss.data[0]))\n",
    "        \n",
    "torch.save(G.state_dict(), './generator.pkl')\n",
    "torch.save(D.state_dict(), './discriminator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
