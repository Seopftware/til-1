{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 밑바닥부터 시작하는 딥러닝 - 이론은 대부분 아는 내용이기에, 직접 구현을 해보고 빠르게 넘어가기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AND(x1, x2):\n",
    "    w1, w2, theta = 0.5, 0.5, 0.7\n",
    "    tmp = x1*w1 + x2*w2\n",
    "    if tmp <= theta:\n",
    "        return 0\n",
    "    elif tmp > theta:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AND2(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.7\n",
    "    tmp = np.sum(w*x)+b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND2(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND2(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND2(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NAND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([-0.5, -0.5])\n",
    "    b = 0.7\n",
    "    tmp = np.sum(w*x)+b\n",
    "    if tmp < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OR(x1, x2):\n",
    "    x = np.array([x1,x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.2\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xor 문제는 퍼셉트론으로 풀 수 없다.\n",
    "# 그러나 직선이라는 제약을 없애면 가능! -> 다층 퍼셉트론을 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XOR(x1, x2):\n",
    "    s1 = NAND(x1,x2)\n",
    "    s2 = OR(x1, x2)\n",
    "    y = AND(s1, s2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 신경망\n",
    "- 활성화함수 : 입력 신호의 총합을 출력 신호로 변환하는 함수\n",
    "- 퍼셉트론은 계단함수를 활성화 함수로 사용!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.arange?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWohwB4AW+n9SUyHBkOuTZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107e935c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "# 기존엔 np.arange([-5.0, 5.0, 0.1])로 했으나 [] 없이 사용 가능하게 변함\n",
    "y = step_function(x)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시그모이드 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([-5.0, 5.0, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00669285,  0.99330715,  0.52497919])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEQ9P8A9nnclg8mQC4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107fe9a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 함수를 사용하면 신경망의 층을 깊게 하는 의미가 없어지기에 비선형 함수를 활성화 함수로 사용!\n",
    "- 선형 함수는 상수배만큼 변하는 함수라, 은닉층이 없는 네트워크로 표현 가능함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU 함수\n",
    "- 입력이 0을 넘으면 그 입력을 그대로 출력하고, 0 이하면 0을 출력하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndim(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1차원도 튜플임\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[1,2],[3,4], [5,6]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndim(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "b = np.array([[5,6], [7,8]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_function(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31682708  0.69627909]\n"
     ]
    }
   ],
   "source": [
    "# 3층 신경망\n",
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "    \n",
    "    return network\n",
    "\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identity_function(a3)\n",
    "    \n",
    "    return y\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 위의 함수는 출력층에서 항등 함수를 사용했습니다. 이번엔 소프트맥스 함수를 사용해보겠습니다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_a = np.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.34985881  18.17414537  54.59815003]\n"
     ]
    }
   ],
   "source": [
    "print(exp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_exp_a = np.sum(exp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.1221542102\n"
     ]
    }
   ],
   "source": [
    "print(sum_exp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = exp_a / sum_exp_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01821127  0.24519181  0.73659691]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "label = t_train[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = img.reshape(28,28) # 784 -> 28 x 28로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open('./ch03/sample_weight.pkl', 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "        \n",
    "    return network\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)\n",
    "    if p == t[i]:\n",
    "#         print(p)\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy:\" +str(float(accuracy_cnt)/len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터를 특정 범위로 변환하는 처리 : 정규화\n",
    "# 입력 데이터에 특정 변환을 가하는 것 : 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 배치 : 하나로 묶은 입력 데이터 (x[0], y[0]엔 0번째 이미지와 그 추론 결과가 저장됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 50)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p ==t[i:i+batch_size])\n",
    "    \n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt)/len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.45490196,\n",
       "        0.49019608,  0.67058825,  1.        ,  1.        ,  0.58823532,\n",
       "        0.36470589,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.66274512,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.85490197,  0.11764706,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.66274512,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.83529413,  0.55686277,  0.6901961 ,\n",
       "        0.99215686,  0.99215686,  0.47843137,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.20392157,  0.98039216,  0.99215686,  0.82352942,  0.1254902 ,\n",
       "        0.04705882,  0.        ,  0.02352941,  0.80784315,  0.99215686,\n",
       "        0.54901963,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.3019608 ,  0.98431373,\n",
       "        0.82352942,  0.09803922,  0.        ,  0.        ,  0.        ,\n",
       "        0.47843137,  0.97254902,  0.99215686,  0.25490198,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.12156863,  0.07058824,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.81960785,  0.99215686,\n",
       "        0.99215686,  0.25490198,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.45882353,  0.96862745,  0.99215686,  0.7764706 ,  0.03921569,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.29803923,  0.96862745,  0.99215686,\n",
       "        0.90588236,  0.24705882,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.50196081,  0.99215686,  0.99215686,  0.56470591,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.6901961 ,  0.96470588,  0.99215686,\n",
       "        0.62352943,  0.04705882,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.09803922,\n",
       "        0.91764706,  0.99215686,  0.9137255 ,  0.13725491,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.7764706 ,  0.99215686,  0.99215686,\n",
       "        0.5529412 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.30588236,\n",
       "        0.97254902,  0.99215686,  0.74117649,  0.04705882,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.07450981,  0.78431374,  0.99215686,  0.99215686,\n",
       "        0.5529412 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.52549022,\n",
       "        0.99215686,  0.99215686,  0.67843139,  0.04705882,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.97254902,  0.99215686,  0.99215686,\n",
       "        0.09803922,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.97254902,  0.99215686,  0.99215686,  0.16862746,  0.07843138,\n",
       "        0.07843138,  0.07843138,  0.07843138,  0.01960784,  0.        ,\n",
       "        0.01960784,  0.07843138,  0.07843138,  0.14509805,  0.58823532,\n",
       "        0.58823532,  0.58823532,  0.57647061,  0.03921569,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.97254902,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.65882355,  0.56078434,  0.65098041,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.48235294,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.68235296,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.97647059,  0.96862745,\n",
       "        0.96862745,  0.66274512,  0.45882353,  0.45882353,  0.22352941,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.4627451 ,  0.48235294,  0.48235294,  0.48235294,  0.65098041,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.60784316,  0.48235294,\n",
       "        0.48235294,  0.16078432,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.45490196,\n",
       "         0.49019608,  0.67058825,  1.        ,  1.        ,  0.58823532,\n",
       "         0.36470589,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.66274512,  0.99215686,  0.99215686,  0.99215686,\n",
       "         0.99215686,  0.99215686,  0.99215686,  0.85490197,  0.11764706,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.66274512,  0.99215686,\n",
       "         0.99215686,  0.99215686,  0.83529413,  0.55686277,  0.6901961 ,\n",
       "         0.99215686,  0.99215686,  0.47843137,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20392157,  0.98039216,  0.99215686,  0.82352942,  0.1254902 ,\n",
       "         0.04705882,  0.        ,  0.02352941,  0.80784315,  0.99215686,\n",
       "         0.54901963,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.3019608 ,  0.98431373,\n",
       "         0.82352942,  0.09803922,  0.        ,  0.        ,  0.        ,\n",
       "         0.47843137,  0.97254902,  0.99215686,  0.25490198,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.12156863,  0.07058824,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.81960785,  0.99215686,\n",
       "         0.99215686,  0.25490198,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.45882353,  0.96862745,  0.99215686,  0.7764706 ,  0.03921569,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.29803923,  0.96862745,  0.99215686,\n",
       "         0.90588236,  0.24705882,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.50196081,  0.99215686,  0.99215686,  0.56470591,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.6901961 ,  0.96470588,  0.99215686,\n",
       "         0.62352943,  0.04705882,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.09803922,\n",
       "         0.91764706,  0.99215686,  0.9137255 ,  0.13725491,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.7764706 ,  0.99215686,  0.99215686,\n",
       "         0.5529412 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.30588236,\n",
       "         0.97254902,  0.99215686,  0.74117649,  0.04705882,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.07450981,  0.78431374,  0.99215686,  0.99215686,\n",
       "         0.5529412 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.52549022,\n",
       "         0.99215686,  0.99215686,  0.67843139,  0.04705882,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.97254902,  0.99215686,  0.99215686,\n",
       "         0.09803922,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.97254902,  0.99215686,  0.99215686,  0.16862746,  0.07843138,\n",
       "         0.07843138,  0.07843138,  0.07843138,  0.01960784,  0.        ,\n",
       "         0.01960784,  0.07843138,  0.07843138,  0.14509805,  0.58823532,\n",
       "         0.58823532,  0.58823532,  0.57647061,  0.03921569,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.97254902,  0.99215686,\n",
       "         0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "         0.99215686,  0.65882355,  0.56078434,  0.65098041,  0.99215686,\n",
       "         0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "         0.99215686,  0.48235294,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.68235296,  0.99215686,  0.99215686,  0.99215686,\n",
       "         0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "         0.99215686,  0.99215686,  0.99215686,  0.97647059,  0.96862745,\n",
       "         0.96862745,  0.66274512,  0.45882353,  0.45882353,  0.22352941,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.4627451 ,  0.48235294,  0.48235294,  0.48235294,  0.65098041,\n",
       "         0.99215686,  0.99215686,  0.99215686,  0.60784316,  0.48235294,\n",
       "         0.48235294,  0.16078432,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9, 0, 1, 2, 9, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 7, 8, 9, 7, 8, 6, 4,\n",
       "       1, 9, 2, 8, 4, 4, 7, 0, 1, 9, 2, 8, 7, 8, 2, 6, 0, 0, 6, 3, 5, 9, 9,\n",
       "       1, 4, 0, 6, 1, 0, 0, 6, 2, 1, 1, 7, 7, 8, 4, 6, 0, 7, 0, 3, 6, 8, 7,\n",
       "       1, 3, 2, 4, 9, 4, 3, 6, 4, 1, 7, 2, 6, 2, 0, 1, 2, 8, 4, 5, 6, 7, 8,\n",
       "       9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4장 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 손실 함수 ( loss function ) = 비용 함수 ( cost function )\n",
    "- 하나의 지표를 기준으로 최적의 매개 변수 값을 탐색하는데, 사용하는 지표를 뜻함\n",
    "- 일반적으로 평균 제곱 오차 ( MSE ) 와 교차 엔트로피 오차를 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평균 제곱 오차 ( Mean Squared Error )\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "E &=& \\frac{1}{2}\\ \\sum_{k=1} (y_k-t_k)^2\\\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray*}\n",
    "y_k = 신경망의 출력(신경망이 추정한 값),  t_k = 정답 레이블, k는 데이터의 차원 수\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y, t):\n",
    "    return 0.5* np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0 ,0]\n",
    "# 정답은 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "# 2일 확률이 가장 높다고 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.097500000000000031"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "# 7일 확률이 가장 높다고 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59750000000000003"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 추정 결과가 오차가 더 작기에 정답에 더 가까운 것으로 판단 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 오차 ( Cross Entropy Error )\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "E &=& - \\sum_{k=1} t_klogy_k\\\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray*}\n",
    "y_k = 신경망의 출력(신경망이 추정한 값),  t_k = 정답 레이블, k는 데이터의 차원 수\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 정하게 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y + delta))\n",
    "# delta를 더하는 이유는 np.log() 안에 0을 입력하면 마이너스 무한대가 되어 계산이 진행되지 않기에..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0 ,0]\n",
    "# 정답은 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "# 2일 확률이 가장 높다고 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51082545709933802"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "# 7일 확률이 가장 높다고 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025840929945458"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치\n",
    "- 훈련 데이터로부터 일부만 골라 학습을 수행. 전체의 근사치로 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y[np.arange(batch_size), t])) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왜 손실 함수를 설정하는가?\n",
    "- 정확도라는 지표를 놔두고 손실 함수의 값을 택하는 이유는?\n",
    "- '미분' : 가중치 매개변수의 값을 아주 조금 벼노하시켰을 때, 손실 함수가 어떻게 변하나?\n",
    "- 최적의 매개변수를 탐색할 때 손실 함수의 값을 간으한 작게 하는 매개 변수 값을 찾습니다. 이때 매개변수의 미분을 계산하고 그 미분값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복\n",
    "\n",
    "\n",
    "### 정확도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 중심 차분 ( 중앙 차분 ) : x를 중심으로 그 전후의 차분을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(0.0, 20.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = function_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEiQU+CIiQUKBLyISJBT4IiJB4v8DeB0dzUhkrZUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb15c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999999999990898"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분 \n",
    "- 변수가 여럿인 함수에 대한 미분\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2+x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 ( gradient ) : 모든 변수의 편미분을 벡터로 정리한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) # x와 형상이 같은 배열 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val -h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  8.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  4.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강법\n",
    "- 현 위치에서 기울어진 방향으로 일정 거리만큼 이동, 그 후 또 기울기를 구해 반복 .. 이렇게 함수의 값을 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## answer : 경사법으로 f(x0,x1) = x0^2 +x1^2의 최솟값을 구하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_x = np.array([-3.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.11110793e-10,   8.14814391e-10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 구현\n",
    "- 1단계 ( 미니배치 ) : 훈련 데이터 중 일부를 무작위로 가져옵니다. 이 미니배치의 손실함수 값을 줄이는 것이 목표\n",
    "- 2단계 ( 기울기 산출 ) : 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구합니다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시\n",
    "- 3단계 ( 매개변수 갱신 ) : 가중치 매개변수를 기울기 방향으로 아주 조금 갱신\n",
    "- 4단계 ( 반복 ) : 1-3단계 반복\n",
    "\n",
    "### 확률적 경사 하강법 ( stochastic gradient descent : SGD )\n",
    "- 확률적으로 무작위로 골라낸 데이터에 대해 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2층 신경망\n",
    "class TwoLayerNEt:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y ==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.two_layer_net import TwoLayerNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.112366666667, 0.1135\n",
      "train acc, test acc | 0.786616666667, 0.7902\n",
      "train acc, test acc | 0.877383333333, 0.8801\n",
      "train acc, test acc | 0.899066666667, 0.9031\n",
      "train acc, test acc | 0.907583333333, 0.9121\n",
      "train acc, test acc | 0.914733333333, 0.9194\n",
      "train acc, test acc | 0.920233333333, 0.9223\n",
      "train acc, test acc | 0.924533333333, 0.9266\n",
      "train acc, test acc | 0.92855, 0.9302\n",
      "train acc, test acc | 0.932333333333, 0.9326\n",
      "train acc, test acc | 0.934966666667, 0.9351\n",
      "train acc, test acc | 0.93775, 0.9384\n",
      "train acc, test acc | 0.939316666667, 0.939\n",
      "train acc, test acc | 0.9418, 0.941\n",
      "train acc, test acc | 0.943966666667, 0.9422\n",
      "train acc, test acc | 0.944933333333, 0.9444\n",
      "train acc, test acc | 0.947366666667, 0.9459\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEu/x9JFD3qNJs1YQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103e6c860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
