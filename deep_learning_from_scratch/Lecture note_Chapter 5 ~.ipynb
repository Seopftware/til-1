{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5. 오차역전파법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수치 미분을 단순하고 구현하기도 쉽지만 계산 시간이 오래 걸린다는 게 단점.\n",
    "- 이번 장에서는 가중치 매개변수의 기울기를 효율적으로 계산하는 '오차역전파법'을 배워보려고 합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 연쇄법칙\n",
    "\n",
    "- 합성 함수 : 여러 함수로 구성된 함수\n",
    "- 합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.\n",
    "\n",
    "\n",
    "## 5.3 역전파\n",
    "- 덧셈의 역전파에서는 상류의 값을 그대로 흘려보내서 순방향 입력 신호의 값은 필요하지 않음\n",
    "- 곱셈의 역전파는 순방향 입력 신호의 값을 필요로 해 순방향 입력 신호의 값이 필요함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None # 순전파시의 입력 값을 유지하기 위해 사용\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x # 상류에서 넘어온 미분에 순전파 값을 바꿔 곱해서 하류로 흘림\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apple_price = mul_apple_layer.forward(apple, apple_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price = mul_tax_layer.forward(apple_price, tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 역전파\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapple_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dapple,dapple_num = mul_apple_layer.backward(dapple_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110.00000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapple_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dOrange: 3.3000000000000003\n",
      "dOrange_num: 165\n",
      "dTax: 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n",
    "price = mul_tax_layer.forward(all_price, tax)  # (4)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\n",
    "\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dOrange:\", dorange)\n",
    "print(\"dOrange_num:\", int(dorange_num))\n",
    "print(\"dTax:\", dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 활성화 함수 계층 구현하기\n",
    "### ReLU 함수! \n",
    "- if x>0, y=x\n",
    "- if x<=0, y=0\n",
    "- 순전파의 입력인 x가 0보다 크면 역전파는 상류의 값을 그대로 하류로 흘립니다. 반면 x가 0 이하면 하류로 신호를 보내지 않음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid\n",
    "- y = 1/(1+exp^(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(Self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 Affine / Softmax 계층 구현하기\n",
    "- 행렬의 내적은 기하학에서는 Affine Transformation이라고 합니다! -> 어파인 변환을 수행하는 처리를 Affine 계층이라고 구현합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6.3 softmax-with-loss 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.7 오차역전파\n",
    "- 1단계 [미니배치] : 훈련 데이터 중 일부를 무작위로 가져옵니다. 이 미니배치의 손실 함수 값을 줄이는 것이 목표\n",
    "- 2단계 [기울기 산출] : 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구합니다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시\n",
    "- 3단계 [매개변수 갱신] : 가중치 매개변수를 기울기 방향으로 아주 조금 갱신\n",
    "- 4단계 [반복] : 1-3단계를 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:2.44021061816e-13\n",
      "b1:9.69523687272e-13\n",
      "W2:9.12763158784e-13\n",
      "b2:1.20126131264e-10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from dataset.mnist import load_mnist\n",
    "# from two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 절대 오차의 평균을 구한다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.160583333333 0.1609\n",
      "0.90315 0.9081\n",
      "0.920966666667 0.9232\n",
      "0.9362 0.9369\n",
      "0.9446 0.9448\n",
      "0.949366666667 0.9462\n",
      "0.957166666667 0.9541\n",
      "0.961133333333 0.9587\n",
      "0.964966666667 0.9608\n",
      "0.967883333333 0.9633\n",
      "0.969983333333 0.9653\n",
      "0.97075 0.9639\n",
      "0.973716666667 0.9667\n",
      "0.976 0.9681\n",
      "0.97675 0.9691\n",
      "0.9787 0.9702\n",
      "0.9789 0.9698\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n",
    "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n",
    "    \n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 학습 관련 기술들\n",
    "## 6.1 SGD\n",
    "- 확률적 경사 하강법\n",
    "- 가장 크게 기울어진 방향으로 가자!\n",
    "- 지그재그로 계석 이동해 비효율적임 (비등방성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.4 모멘텀\n",
    "- 운동량을 뜻함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "                \n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 인스턴스 변수 v가 물체의 속도.\n",
    "# SGD와 비교하면 지그재그 정도가 덜함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.5 AdaGrad\n",
    "- 각각의 매개 변수에 맞춤형 값을 만들어줌\n",
    "- 개별 매개변수에 적응적으로 학습률을 조정하면서 학습을 진행\n",
    "- h : 기존 기울기값을 제곱해 계속 더해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            \n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.key():\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.6 Adam\n",
    "- 모멘텀 + AdaGrad\n",
    "- 더 궁금하다면 원 논문을 확인\n",
    "\n",
    "\n",
    "### SGD, 모멘텀, AdaGrad, Adam 중 어떤 것이 빠르다! 이런 것은 아직 없음. 학습률과 신경망 구조에 따라 결과가 달라짐.\n",
    "### 다만 일반적으로 SGD보다 다른 세 기법이 빠르게 학습하고, 떄로는 최종 정확도도 높게 나타남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 초기값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 초기값을 모두 0을 하면 안되는 이유 : 오차역전파법에서 모든 가중치의 값이 똑같이 갱신되기 떄문에..!\n",
    "- 은닉층의 활성화값의 분포를 관찰하면 중요한 정보를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1050aac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "    \n",
    "input_data = np.random.randn(1000, 100)  # 1000개의 데이터\n",
    "node_num = 100  # 각 은닉층의 노드(뉴런) 수\n",
    "hidden_layer_size = 5  # 은닉층이 5개\n",
    "activations = {}  # 이곳에 활성화 결과를 저장\n",
    "\n",
    "x = input_data\n",
    "\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "\n",
    "    # 초깃값을 다양하게 바꿔가며 실험해보자！\n",
    "#     w = np.random.randn(node_num, node_num) * 1\n",
    "#     w = np.random.randn(node_num, node_num) * 0.01\n",
    "    w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
    "    # w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
    "\n",
    "\n",
    "    a = np.dot(x, w)\n",
    "\n",
    "\n",
    "    # 활성화 함수도 바꿔가며 실험해보자！\n",
    "    z = sigmoid(a)\n",
    "    # z = ReLU(a)\n",
    "    # z = tanh(a)\n",
    "\n",
    "    activations[i] = z\n",
    "\n",
    "# 히스토그램 그리기\n",
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + \"-layer\")\n",
    "    if i != 0: plt.yticks([], [])\n",
    "    # plt.xlim(0.1, 1)\n",
    "    # plt.ylim(0, 7000)\n",
    "    plt.hist(a.flatten(), 30, range=(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (가중치의 표준 편차:1) 데이터가 0과 1에 치우쳐 분포하게 되면 역전파의 기울기 값이 점점 작아지다 사라짐 -> 기울기 소실 (gradient vanishing)\n",
    "# (가중치의 표준 편차:0.01) 데이터가 0.5 부근에 집중. 치우치는 경우 표현력을 제한하는 관점에서 문제."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xaviear 초기값\n",
    "- 초기값의 표준편차가 1/(루트n) 이 되도록 설정 (n은 앞 층의 노드 수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU를 사용할 경우\n",
    "- ReLU에 특화된 초기값 : He 초기값\n",
    "- 노드가 n개일 때, 표준편차가 루트2/n인 정규분포를 사용! ReLU는 음의 영역이 0이라서 더 넓게 분포시키기 위해 2배의 계수가 필요하다고 해석..!\n",
    "\n",
    "# 간단 정리\n",
    "- 활성화 함수 ReLU : He 초기값\n",
    "- 활성화 함수 Sigmoid, tanh등의 S자 곡선 : Xavier 초기값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========iteration:0===========\n",
      "std=0.01:2.30250013217\n",
      "Xavier:2.32583477772\n",
      "He:2.35230525879\n",
      "===========iteration:100===========\n",
      "std=0.01:2.3021881685\n",
      "Xavier:2.26317348624\n",
      "He:1.51987125075\n",
      "===========iteration:200===========\n",
      "std=0.01:2.30169521978\n",
      "Xavier:2.14815886623\n",
      "He:0.764672690242\n",
      "===========iteration:300===========\n",
      "std=0.01:2.30276137624\n",
      "Xavier:1.90363370175\n",
      "He:0.55631896597\n",
      "===========iteration:400===========\n",
      "std=0.01:2.29914678388\n",
      "Xavier:1.46670421694\n",
      "He:0.407639640155\n",
      "===========iteration:500===========\n",
      "std=0.01:2.30170721926\n",
      "Xavier:0.950188535012\n",
      "He:0.351653130484\n",
      "===========iteration:600===========\n",
      "std=0.01:2.30113227241\n",
      "Xavier:0.740427167198\n",
      "He:0.339266496633\n",
      "===========iteration:700===========\n",
      "std=0.01:2.30144413638\n",
      "Xavier:0.499892023207\n",
      "He:0.247046717246\n",
      "===========iteration:800===========\n",
      "std=0.01:2.29804459384\n",
      "Xavier:0.469626753554\n",
      "He:0.254507897572\n",
      "===========iteration:900===========\n",
      "std=0.01:2.29292654132\n",
      "Xavier:0.387462353606\n",
      "He:0.220948370333\n",
      "===========iteration:1000===========\n",
      "std=0.01:2.30348985837\n",
      "Xavier:0.357247670121\n",
      "He:0.212871898058\n",
      "===========iteration:1100===========\n",
      "std=0.01:2.2996220664\n",
      "Xavier:0.304958826899\n",
      "He:0.237749971155\n",
      "===========iteration:1200===========\n",
      "std=0.01:2.29538685018\n",
      "Xavier:0.284957252115\n",
      "He:0.192860035043\n",
      "===========iteration:1300===========\n",
      "std=0.01:2.29474144407\n",
      "Xavier:0.333086640384\n",
      "He:0.264190820158\n",
      "===========iteration:1400===========\n",
      "std=0.01:2.30213848038\n",
      "Xavier:0.617269935613\n",
      "He:0.488722135992\n",
      "===========iteration:1500===========\n",
      "std=0.01:2.30167629746\n",
      "Xavier:0.459697020328\n",
      "He:0.343314826272\n",
      "===========iteration:1600===========\n",
      "std=0.01:2.30131246614\n",
      "Xavier:0.222582410036\n",
      "He:0.135876607239\n",
      "===========iteration:1700===========\n",
      "std=0.01:2.30170926932\n",
      "Xavier:0.244932445099\n",
      "He:0.170558286296\n",
      "===========iteration:1800===========\n",
      "std=0.01:2.30139115423\n",
      "Xavier:0.349703029286\n",
      "He:0.257463013812\n",
      "===========iteration:1900===========\n",
      "std=0.01:2.29821756083\n",
      "Xavier:0.182799369128\n",
      "He:0.123903378041\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZVbhTMzKzKjYKZmVX9HxGNFV8qlUGgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106abb4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common.util import smooth_curve\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import SGD\n",
    "\n",
    "\n",
    "# 0. MNIST 데이터 읽기==========\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 128\n",
    "max_iterations = 2000\n",
    "\n",
    "\n",
    "# 1. 실험용 설정==========\n",
    "weight_init_types = {'std=0.01': 0.01, 'Xavier': 'sigmoid', 'He': 'relu'}\n",
    "optimizer = SGD(lr=0.01)\n",
    "\n",
    "networks = {}\n",
    "train_loss = {}\n",
    "for key, weight_type in weight_init_types.items():\n",
    "    networks[key] = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
    "                                  output_size=10, weight_init_std=weight_type)\n",
    "    train_loss[key] = []\n",
    "\n",
    "\n",
    "# 2. 훈련 시작==========\n",
    "for i in range(max_iterations):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    for key in weight_init_types.keys():\n",
    "        grads = networks[key].gradient(x_batch, t_batch)\n",
    "        optimizer.update(networks[key].params, grads)\n",
    "    \n",
    "        loss = networks[key].loss(x_batch, t_batch)\n",
    "        train_loss[key].append(loss)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"===========\" + \"iteration:\" + str(i) + \"===========\")\n",
    "        for key in weight_init_types.keys():\n",
    "            loss = networks[key].loss(x_batch, t_batch)\n",
    "            print(key + \":\" + str(loss))\n",
    "\n",
    "\n",
    "# 3. 그래프 그리기==========\n",
    "markers = {'std=0.01': 'o', 'Xavier': 's', 'He': 'D'}\n",
    "x = np.arange(max_iterations)\n",
    "for key in weight_init_types.keys():\n",
    "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6.3 배치 정규화\n",
    "- 2015년에 제안된 방법\n",
    "### 배치 정규화가 주목받는 이유\n",
    "- 학습을 빨리 진행할 수 있음 ( 학습 속도 개선 )\n",
    "- 초깃값에 크게 의존하지 않음 ( 초깃값 선택 장애 제거 )\n",
    "- 오버피팅을 억제 ( 드롭아웃 등의 필요성 감소 )\n",
    "\n",
    "\n",
    "- 학습시 미니배치를 단위로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 바른 학습을 위해\n",
    "## 오버피팅\n",
    "- 매개변수가 많고 표현력이 높은 모델\n",
    "- 훈련 데이터가 적음\n",
    "\n",
    "위 2가지 경우에 일어납니다\n",
    "\n",
    "훈련 데이터에 최적화되고, 새 데이터가 들어왔을 경우 올바른 값을 내놓지 못합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.2 가중치 감소\n",
    "- 큰 가중치에 대해서 그에 상응하는 큰 페널티 부과\n",
    "### 정규화\n",
    "1. 릿지 ( 제곱 ) => 설명력이 아쉬운 편\n",
    "2. 라쏘 ( 절대값 ) => 변수 선택 가능. 중요하지 않은 값은 0으로!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4.3 드롭아웃\n",
    "- 뉴런을 임의로 삭제하면서 학습하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 하이퍼 파라미터 튜닝\n",
    "- 각 층의 뉴런 수, 배치 크기, 매개변수 갱신 시의 학습률과 가중치 막소등을 하이퍼 파라미터라고 칭합니다\n",
    "- 훈련 데이터 + 시험 데이터에서 검증 데이터까지 추가!\n",
    "\n",
    "\n",
    "- 훈련 데이터 : 매개변수 학습\n",
    "- 검증 데이터 : 하이퍼파라미터 성능 평가\n",
    "- 시험 데이터 : 신경망의 범용 성능 평가\n",
    "\n",
    "- 신경망의 하이퍼 파라미터 최적화는 그리드 서치같은 규칙적 탐색보다 무작위 샘플링해 탐색하는 편이 좋은 결과를 낸다고 알려짐\n",
    "- 베이즈 최적화란 것도 있으니 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 합성곱 신경망 (CNN)\n",
    "- 기존에 본 Affine 계층 : 인접하는 계층의 모든 뉴런과 결합된 형태로 **완전연결**이라고 합니다\n",
    "- 완전연결 신경망은 데이터의 형상이 무시됩니다..!\n",
    "- **합성곱 계층**은 형상을 유지합니다. 이미지도 3차원 데이터로 입력 받으며 다음 계층에도 3차원으로 전달합니다\n",
    "\n",
    "#### 기본 용어\n",
    "- 특징 맵 ( feature map ) : 입출력 데이터\n",
    "- 입력 특징 맵 : 입력 데이터 / 출력 특징 맵 : 출력 데이터\n",
    "- 필터(커널)\n",
    "- 윈도우 : 간격\n",
    "\n",
    "- 패딩(padding) : 입력 데이터 주변을 특정 값(예를 들어 0) 으로 채움. => 출력 크기를 조정할 목적으로 사용! ( 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수 있음)\n",
    "- 스트라이드(stride) : 필터를 적용하는 위치의 간격\n",
    "\n",
    "\n",
    "- 입력 크기 : (H,W), 필터 크기 : (FH, FW), 출력 크기 : (OH,OW), 패딩 : P, 스트라이드 : S일 경우\n",
    "- OH = (H+2P-FH)/S + 1\n",
    "- OW = (W+2P-FW)/S +1\n",
    "\n",
    "### 풀링 계층\n",
    "- 풀링 : 세로, 가로 방향의 공간을 줄이는 연산\n",
    "- 최대 풀링(max pooling) : 영역에서 가장 큰 원소 하나를 꺼냄\n",
    "- 풀링 계층은 학습해야 할 매개변수가 없음! ( 대상 영역에서 최대값이나 평균을 취할뿐 )\n",
    "- 채널 수가 변하지 않음!\n",
    "- 입럭의 변화에 영향을 적게 받음 ( 강건함 )\n",
    "\n",
    "#### 4차원 배열\n",
    "- cnn에서 계층 사이를 흐르는 데이터는 4차원입니다. 형사이 (10, 1, 28, 28)이라면 높이 28, 너비 28, 채널 1개인 데이터가 10개라는 이야기입니다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(10, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10개중 첫번째 데이터에 접근할 경우\n",
    "x[0].shape # (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09211   ,  0.88611347,  0.03338694,  0.11837624,  0.85346941,\n",
       "         0.82445568,  0.67712597,  0.75344537,  0.41279763,  0.9786374 ,\n",
       "         0.06177778,  0.54654415,  0.70927364,  0.81731501,  0.32906787,\n",
       "         0.91914508,  0.84191272,  0.94901348,  0.69158681,  0.68817398,\n",
       "         0.30451515,  0.76329848,  0.26899127,  0.18918015,  0.25294696,\n",
       "         0.58280302,  0.0698739 ,  0.11434238],\n",
       "       [ 0.3622673 ,  0.1306698 ,  0.43508386,  0.96641739,  0.05746673,\n",
       "         0.15057794,  0.57228972,  0.09908588,  0.90933671,  0.14057865,\n",
       "         0.99178052,  0.78921387,  0.69225798,  0.44209711,  0.1254271 ,\n",
       "         0.38730976,  0.2373709 ,  0.95123871,  0.98739262,  0.96888392,\n",
       "         0.0534259 ,  0.14521333,  0.61110983,  0.43947422,  0.62318854,\n",
       "         0.07193239,  0.62506054,  0.67097061],\n",
       "       [ 0.22025308,  0.32825662,  0.28196533,  0.07340701,  0.4125856 ,\n",
       "         0.78048303,  0.14739731,  0.43066468,  0.10117215,  0.39310761,\n",
       "         0.41029203,  0.13699816,  0.64414545,  0.43672635,  0.77051773,\n",
       "         0.48028154,  0.19854356,  0.0916335 ,  0.48409555,  0.57767177,\n",
       "         0.68754562,  0.47383857,  0.65973384,  0.98889392,  0.07253928,\n",
       "         0.45708147,  0.53822804,  0.39644366],\n",
       "       [ 0.23205839,  0.66031203,  0.74982189,  0.41152903,  0.94138352,\n",
       "         0.65343267,  0.25550879,  0.98672972,  0.90890396,  0.51151772,\n",
       "         0.8612635 ,  0.66111445,  0.19421344,  0.64179276,  0.59291089,\n",
       "         0.04638033,  0.51609354,  0.97954258,  0.67368711,  0.92397668,\n",
       "         0.30757679,  0.77543611,  0.88372949,  0.4742913 ,  0.92910338,\n",
       "         0.52242679,  0.54032056,  0.75271146],\n",
       "       [ 0.11732179,  0.44886733,  0.15918212,  0.04326526,  0.62685424,\n",
       "         0.32171917,  0.78822472,  0.69238248,  0.73861466,  0.10985449,\n",
       "         0.58232578,  0.0303046 ,  0.40167435,  0.62169518,  0.66068847,\n",
       "         0.87253976,  0.48251386,  0.81813818,  0.9768198 ,  0.23927174,\n",
       "         0.03154767,  0.10538988,  0.63748637,  0.41780498,  0.89781559,\n",
       "         0.37444358,  0.66090897,  0.83340193],\n",
       "       [ 0.7367635 ,  0.60494691,  0.47663467,  0.68141929,  0.25452928,\n",
       "         0.04515531,  0.33590696,  0.635615  ,  0.84698121,  0.26489746,\n",
       "         0.80001852,  0.07564665,  0.71376569,  0.81364038,  0.64170622,\n",
       "         0.59917309,  0.77624866,  0.85831076,  0.24278495,  0.43547951,\n",
       "         0.75956253,  0.29373463,  0.87321843,  0.78063533,  0.03564499,\n",
       "         0.94235504,  0.37070245,  0.19957881],\n",
       "       [ 0.32315806,  0.36319198,  0.84623119,  0.15024932,  0.21116902,\n",
       "         0.93703544,  0.68195116,  0.39694756,  0.26995047,  0.43782475,\n",
       "         0.92386588,  0.77921213,  0.84258579,  0.59841196,  0.02551836,\n",
       "         0.82642913,  0.68246751,  0.08672305,  0.95437054,  0.92600196,\n",
       "         0.1518558 ,  0.66732412,  0.60140689,  0.2476416 ,  0.8835245 ,\n",
       "         0.25268129,  0.0097991 ,  0.14841814],\n",
       "       [ 0.64938058,  0.3734744 ,  0.33470626,  0.25763479,  0.79660737,\n",
       "         0.12615508,  0.71687296,  0.15586646,  0.3050842 ,  0.97300219,\n",
       "         0.93594257,  0.96681685,  0.14745224,  0.43220689,  0.71772198,\n",
       "         0.04040675,  0.44060492,  0.65471497,  0.74534659,  0.03497456,\n",
       "         0.45604256,  0.15023019,  0.32765362,  0.18977117,  0.69171802,\n",
       "         0.9753667 ,  0.88657664,  0.43357514],\n",
       "       [ 0.19556737,  0.815197  ,  0.99316916,  0.94315961,  0.53657231,\n",
       "         0.70187641,  0.67555623,  0.53620246,  0.19089169,  0.79998435,\n",
       "         0.16273554,  0.13531499,  0.57614881,  0.43384273,  0.72271044,\n",
       "         0.48554604,  0.59988173,  0.70782909,  0.8856578 ,  0.26223312,\n",
       "         0.5090961 ,  0.67318802,  0.11704007,  0.69147516,  0.89060919,\n",
       "         0.70359594,  0.15622893,  0.12933855],\n",
       "       [ 0.47369453,  0.69254696,  0.58325608,  0.67633345,  0.39663478,\n",
       "         0.61976242,  0.14105226,  0.14818086,  0.18285866,  0.39895948,\n",
       "         0.90763306,  0.45235656,  0.59258615,  0.77176927,  0.96819371,\n",
       "         0.01438966,  0.60408867,  0.05934762,  0.60117986,  0.7322025 ,\n",
       "         0.74864047,  0.38988696,  0.57894581,  0.03834019,  0.43151849,\n",
       "         0.75547792,  0.51500248,  0.53712032],\n",
       "       [ 0.27720546,  0.28582898,  0.53927268,  0.19432133,  0.42690129,\n",
       "         0.44452502,  0.06076718,  0.91644239,  0.31508785,  0.26635102,\n",
       "         0.34705416,  0.25652136,  0.87947645,  0.22438045,  0.35213173,\n",
       "         0.85315294,  0.42409344,  0.82580565,  0.86943487,  0.19618161,\n",
       "         0.21821465,  0.77597408,  0.48274297,  0.43338511,  0.83524042,\n",
       "         0.20367715,  0.73890029,  0.15452276],\n",
       "       [ 0.43769762,  0.36850644,  0.5957186 ,  0.81548736,  0.23507854,\n",
       "         0.32513038,  0.77572476,  0.44588527,  0.46994598,  0.24381092,\n",
       "         0.56747534,  0.0412158 ,  0.25523618,  0.35302522,  0.64612649,\n",
       "         0.74957148,  0.94499317,  0.81378141,  0.71297444,  0.66960712,\n",
       "         0.38993828,  0.19862167,  0.26610611,  0.06263692,  0.59198063,\n",
       "         0.3537115 ,  0.69523794,  0.79305691],\n",
       "       [ 0.46628251,  0.48442466,  0.50861233,  0.41145227,  0.78302448,\n",
       "         0.72451471,  0.45236061,  0.84305103,  0.18893546,  0.25582966,\n",
       "         0.34495643,  0.83130264,  0.54982424,  0.61870225,  0.83538443,\n",
       "         0.57219876,  0.633091  ,  0.82736596,  0.4213031 ,  0.60260686,\n",
       "         0.3770213 ,  0.84440118,  0.33969952,  0.90778709,  0.04636707,\n",
       "         0.65609861,  0.52821797,  0.69287932],\n",
       "       [ 0.37107579,  0.48711644,  0.3089661 ,  0.31853645,  0.22777716,\n",
       "         0.81840582,  0.27355304,  0.5394094 ,  0.80999804,  0.04812952,\n",
       "         0.06816038,  0.27326651,  0.02710675,  0.70616931,  0.68662948,\n",
       "         0.51510262,  0.01421615,  0.66485745,  0.44904176,  0.71258744,\n",
       "         0.61745009,  0.5453533 ,  0.78588521,  0.98487498,  0.27136972,\n",
       "         0.51940391,  0.92678725,  0.76320926],\n",
       "       [ 0.29125999,  0.67262035,  0.2116745 ,  0.84619263,  0.94819084,\n",
       "         0.25501211,  0.92206661,  0.79718575,  0.46354874,  0.68379824,\n",
       "         0.61151035,  0.78958786,  0.15205469,  0.50547587,  0.94471303,\n",
       "         0.64794895,  0.9106678 ,  0.89538946,  0.02602997,  0.00298503,\n",
       "         0.80023963,  0.95195247,  0.39021839,  0.38230255,  0.31859881,\n",
       "         0.77014412,  0.59116198,  0.29485656],\n",
       "       [ 0.77739837,  0.5102995 ,  0.30904432,  0.81710203,  0.54597191,\n",
       "         0.83536748,  0.40127224,  0.13636929,  0.04899248,  0.51814953,\n",
       "         0.01997717,  0.1631755 ,  0.2262224 ,  0.48023996,  0.39045276,\n",
       "         0.21851618,  0.37046725,  0.29806333,  0.00339643,  0.69129015,\n",
       "         0.14290364,  0.11054508,  0.62918643,  0.36810594,  0.40313006,\n",
       "         0.95414669,  0.46055937,  0.15065429],\n",
       "       [ 0.70513109,  0.48817345,  0.32536322,  0.43061415,  0.22272596,\n",
       "         0.30206296,  0.40506522,  0.39881061,  0.01933932,  0.64642764,\n",
       "         0.37124238,  0.93297537,  0.81064589,  0.69780283,  0.01729943,\n",
       "         0.78910807,  0.11150681,  0.68371916,  0.33673367,  0.40329741,\n",
       "         0.89987517,  0.37981965,  0.64394211,  0.052468  ,  0.96088178,\n",
       "         0.7925476 ,  0.75511128,  0.04860443],\n",
       "       [ 0.71887432,  0.42109617,  0.96739052,  0.8666633 ,  0.23811203,\n",
       "         0.91403106,  0.80708214,  0.27519169,  0.97972708,  0.42702249,\n",
       "         0.06579486,  0.00117587,  0.72422759,  0.53668204,  0.91974474,\n",
       "         0.48491022,  0.16672079,  0.04425113,  0.67401711,  0.40810968,\n",
       "         0.93242556,  0.70963681,  0.21548512,  0.31930794,  0.44039531,\n",
       "         0.50908557,  0.10837227,  0.92037425],\n",
       "       [ 0.19675062,  0.03766374,  0.66265141,  0.78090152,  0.50843046,\n",
       "         0.62003027,  0.10442348,  0.2244516 ,  0.25422853,  0.01779612,\n",
       "         0.95583507,  0.21569091,  0.65909084,  0.48480616,  0.19344839,\n",
       "         0.56039774,  0.42844506,  0.30728715,  0.88111153,  0.58586982,\n",
       "         0.36058679,  0.75776033,  0.69213716,  0.61930321,  0.0381257 ,\n",
       "         0.63271461,  0.19356491,  0.99237951],\n",
       "       [ 0.08093473,  0.51131929,  0.83042886,  0.57663886,  0.0436608 ,\n",
       "         0.67267269,  0.77228447,  0.47715803,  0.82182754,  0.10927522,\n",
       "         0.08647615,  0.46352191,  0.10003138,  0.48202298,  0.08339773,\n",
       "         0.65140534,  0.56740208,  0.62035462,  0.95111632,  0.44720885,\n",
       "         0.11345554,  0.16723808,  0.86644158,  0.20237614,  0.97182423,\n",
       "         0.592789  ,  0.39012327,  0.69802975],\n",
       "       [ 0.66323512,  0.91872224,  0.40276089,  0.93221671,  0.79829963,\n",
       "         0.53982581,  0.46454524,  0.42837166,  0.15405167,  0.9607919 ,\n",
       "         0.33269502,  0.36137211,  0.24113823,  0.25142527,  0.27437929,\n",
       "         0.72880969,  0.57581607,  0.87604117,  0.48870009,  0.18053089,\n",
       "         0.20408722,  0.17997407,  0.58198084,  0.75622123,  0.37264146,\n",
       "         0.02068394,  0.41446214,  0.53479852],\n",
       "       [ 0.41038826,  0.41404297,  0.97977077,  0.92235588,  0.09606079,\n",
       "         0.83805842,  0.49260594,  0.27602975,  0.46051438,  0.67184523,\n",
       "         0.2110997 ,  0.24853366,  0.95870164,  0.07271667,  0.32255957,\n",
       "         0.35967236,  0.15559526,  0.78926662,  0.35196058,  0.55285492,\n",
       "         0.70650513,  0.81089481,  0.00905696,  0.3548584 ,  0.86812971,\n",
       "         0.05074057,  0.57215211,  0.38446797],\n",
       "       [ 0.50370373,  0.15597325,  0.75950644,  0.91285612,  0.12306102,\n",
       "         0.34561146,  0.34238383,  0.38914034,  0.24487151,  0.76342945,\n",
       "         0.41002052,  0.87963303,  0.68985381,  0.47995031,  0.04159881,\n",
       "         0.11381687,  0.8862299 ,  0.18466023,  0.15179469,  0.01334483,\n",
       "         0.85015984,  0.61130072,  0.3443518 ,  0.88597043,  0.53852247,\n",
       "         0.44383128,  0.68400064,  0.9895926 ],\n",
       "       [ 0.21955466,  0.80729851,  0.93116517,  0.40915135,  0.14658317,\n",
       "         0.04126153,  0.53652022,  0.90130884,  0.0315267 ,  0.64619069,\n",
       "         0.25272418,  0.88663683,  0.54692796,  0.07611252,  0.6220977 ,\n",
       "         0.75552896,  0.70645979,  0.78563864,  0.38033433,  0.34870986,\n",
       "         0.27843828,  0.15399127,  0.34144942,  0.18303704,  0.30108157,\n",
       "         0.34054982,  0.76311339,  0.61199018],\n",
       "       [ 0.5343518 ,  0.10580627,  0.71347409,  0.30170114,  0.03852429,\n",
       "         0.69765553,  0.78377049,  0.92554572,  0.26174344,  0.91462395,\n",
       "         0.09058043,  0.33021855,  0.48313257,  0.17657974,  0.99337714,\n",
       "         0.27714266,  0.78913899,  0.31770097,  0.79433272,  0.90394174,\n",
       "         0.04146248,  0.41862291,  0.69395343,  0.54864939,  0.97270194,\n",
       "         0.90188397,  0.89627718,  0.26329877],\n",
       "       [ 0.13785289,  0.2369665 ,  0.81065944,  0.35112292,  0.11071253,\n",
       "         0.32730674,  0.67940745,  0.45438614,  0.47674277,  0.14352213,\n",
       "         0.92512387,  0.50597848,  0.64297765,  0.66228668,  0.99529489,\n",
       "         0.76437855,  0.38279992,  0.54534162,  0.88379813,  0.69888269,\n",
       "         0.4525373 ,  0.71813781,  0.01958873,  0.6076792 ,  0.55730873,\n",
       "         0.65647135,  0.85834424,  0.15782743],\n",
       "       [ 0.64725122,  0.73398576,  0.2471206 ,  0.05409791,  0.43627499,\n",
       "         0.75369314,  0.22019081,  0.49980924,  0.48938526,  0.97924054,\n",
       "         0.10144246,  0.9950462 ,  0.17654071,  0.11837694,  0.17602872,\n",
       "         0.76054799,  0.4080585 ,  0.71744041,  0.65489501,  0.47293557,\n",
       "         0.56527288,  0.95577475,  0.78054378,  0.78949026,  0.37424134,\n",
       "         0.02724681,  0.00447662,  0.22569172],\n",
       "       [ 0.95245939,  0.51899122,  0.82346021,  0.38973234,  0.91649895,\n",
       "         0.79474183,  0.80381723,  0.07292486,  0.87054713,  0.32827649,\n",
       "         0.79383083,  0.51626175,  0.75355265,  0.12508966,  0.68088176,\n",
       "         0.65662732,  0.99766538,  0.12674099,  0.20672617,  0.23899053,\n",
       "         0.67796278,  0.17172732,  0.13902043,  0.34355152,  0.57489712,\n",
       "         0.45179743,  0.29698358,  0.16032762]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 데이터의 첫 채널 공간에 접근할 경우\n",
    "x[0, 0] # 또는 x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 im2col로 데이터 전개하기\n",
    "- numpy에서는 for문을 사용하지 않는 것이 바람직하기에 im2col이라는 편의 함수를 구현! \n",
    "- 메모리를 더 많이 소비하는 단점이 있음..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common.util import im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_data : (데이터 수, 채널 수, 높이, 너비)\n",
    "# filter_h - 필터의 높이\n",
    "# filter_w - 필터의 너비\n",
    "# stride - 스트라이드\n",
    "# pad - 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n"
     ]
    }
   ],
   "source": [
    "print(col1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 = np.random.rand(10, 3, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T # 필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape에 -1을 지정하면 다차원 배열의 원소 수가 변환 후에도 똑같이 유지되도록 적절히 묶어줌!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + ( H - self.pool_h) / self.stride )\n",
    "        out_w = int(1 + ( W - self.pool_w) / self.stride )\n",
    "        \n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3,1,2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEjCAYAAABD3BobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIoAADj/D1tD8Nbi6jffAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108f652b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEjCAYAAABD3BobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwKEUAQBwKEUAABxKEQAAh1IEAMD5P1+p1coizE39AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108f47320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
