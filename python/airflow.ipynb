{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.operators.mysql_operator import MySqlOperator\n",
    "from gcloud import storage\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta, SU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'sy',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2018, 1, 8),\n",
    "    'email': ['snugyun01@gmail.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': True,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dag = DAG('first_dag', description='dag', default_args=default_args,\n",
    "          schedule_interval='1 0 * * 1', catchup=False)\n",
    "\n",
    "\n",
    "t = date.today() + relativedelta(weekday=SU(-2))\n",
    "suffix = t.strftime(\"%Y%m%d\")\n",
    "\n",
    "first_task = BashOperator(\n",
    "                    task_id='first_task_ios_{}'.format(t),\n",
    "                    bash_command='bash script1.sh ios {t}'.format(t=t),\n",
    "                    dag=dag)\n",
    "\n",
    "second_task = BashOperator(\n",
    "                    task_id='second_task_ios_{}'.format(t),\n",
    "                    bash_command='bash script2.sh ios {t}'.format(t=t),\n",
    "                    dag=dag)\n",
    "\n",
    "# Google Storage Bucket에 있는 파일 개수 체크\n",
    "client = storage.Client(project='project-name')\n",
    "bucket = client.bucket(\"bucket-name\")\n",
    "blobs_file_ios = bucket.list_blobs(prefix='prefix_file_name_{}'.format(suffix))\n",
    "\n",
    "query = \"LOAD DATA LOCAL INFILE '~/airflow/download/{}' INTO TABLE {table} CHARACTER SET utf8 \" \\\n",
    "        \"FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\\\n' IGNORE 1 LINES \"\n",
    "\n",
    "i = 0\n",
    "bulk_insert_tasks = []\n",
    "for blob in blobs_file_ios:\n",
    "    blob_name = blob.name\n",
    "    file_name = blob_name.split(\"/\")[2]\n",
    "    task = MySqlOperator(task_id='insert_{}_{}'.format(t, i),\n",
    "                         sql=query.format(file_name), mysql_conn_id='mysql_default', dag=dag)\n",
    "    bulk_insert_tasks.append(task)\n",
    "    i += 1\n",
    "\n",
    "\n",
    "first_task >> second_task\n",
    "second_task >> bulk_insert_tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. for문 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client.from_service_account_json(\"json_key\", project='project-name')\n",
    "bucket = client.bucket(\"bucket-name\")\n",
    "\n",
    "def bulk_insert(*args, **kwargs):\n",
    "    ed = kwargs.get('execution_date') + relativedelta(weekday=SU(-2))\n",
    "    platform = kwargs.get('platform')\n",
    "    date = ed.strftime(\"%Y%m%d\")\n",
    "\n",
    "    blobs_file_ios = bucket.list_blobs(prefix=\"tmp/log/data_{}_{}\".format(platform, date))\n",
    "    connection = MySQLdb.Connect(host='localhost', user='root', passwd='password', db='db', local_infile=1)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"SET innodb_lock_wait_timeout = 360;\")\n",
    "    cursor.execute(\"SET FOREIGN_KEY_CHECKS = 0;\")\n",
    "    cursor.execute(\"SET UNIQUE_CHECKS = 0;\")\n",
    "\n",
    "    for blob in blobs_file_ios:\n",
    "        blob_name = blob.name\n",
    "        file_name = blob_name.split(\"/\")[2]\n",
    "        query_format = \"LOAD DATA LOCAL INFILE '~/download/{}' REPLACE INTO TABLE database.table_{} CHARACTER SET utf8 FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\\\n' IGNORE 1 LINES \" \\\n",
    "                       \"(user_id, instance_id, platform, app_version, country, first_week, event_week, diff_week); \"\n",
    "        query = query_format.format(file_name, platform)\n",
    "        cursor.execute(query)\n",
    "\n",
    "    cursor.execute(\"SET FOREIGN_KEY_CHECKS = 1;\")\n",
    "    cursor.execute(\"SET UNIQUE_CHECKS = 1;\")\n",
    "    connection.commit()\n",
    "\n",
    "    return 'success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"{{ macros.ds_add(ds, -9) }}\"\n",
    "\n",
    "agg_query = \"INSERT INTO database.table_{platform} (`country`, `platform`, `first_week`, `diff_week`, `retain`)\\n \" \\\n",
    "            \"SELECT a.country AS country, a.platform AS platform, a.first_week AS first_week, a.diff_week AS diff_week, COUNT(DISTINCT instance_id) AS retain \\n \" \\\n",
    "            \"FROM database.table_log_{platform} AS a GROUP BY country, platform, first_week, diff_week ON DUPLICATE KEY UPDATE retain = retain; \"\n",
    "\n",
    "\n",
    "for platform in ['ios', 'android']:\n",
    "    query_task = BashOperator(task_id='query_task_{}_{}'.format(platform, t),\n",
    "                              bash_command='bash cron.sh retention_query {} '.format(platform) + date,\n",
    "                              dag=dag)\n",
    "\n",
    "    extract_task = BashOperator(task_id='extract_task_{}_{}'.format(platform, t),\n",
    "                                bash_command='bash cron.sh extract {} '.format(platform) + date,\n",
    "                                dag=dag)\n",
    "\n",
    "    download_task = BashOperator(task_id='download_task_{}_{}'.format(platform, t),\n",
    "                                 bash_command='bash cron.sh download {} '.format(platform) + date,\n",
    "                                 dag=dag)\n",
    "\n",
    "    bulk_insert_task = PythonOperator(task_id='bulk_insert_{}'.format(platform), python_callable=bulk_insert,\n",
    "                                      dag=dag, provide_context=True, op_kwargs={'platform': platform})\n",
    "\n",
    "    retention_agg_task = MySqlOperator(task_id='retention_agg_task_{}_{}'.format(platform, t),\n",
    "                                       sql=agg_query.format(platform=platform), mysql_conn_id='mysql_default', dag=dag)\n",
    "\n",
    "    query_task >> extract_task >> download_task >> bulk_insert_task >> retention_agg_task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
